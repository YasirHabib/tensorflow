{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist_th.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasirHabib/tensorflow/blob/master/fashion_mnist_th.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW9rgNoaRcWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2zXzttxR4ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import theano.tensor as T\n",
        "import theano"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbaMwb3QSb9S",
        "colab_type": "code",
        "outputId": "81c7ff65-6478-4f11-fff9-a939918444f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJOOHLcCSc0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/fashion-mnist_train.csv')\n",
        "df_test = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/fashion-mnist_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Gckz8JVW5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizer_update(cost, parameters, lr):\n",
        "  grads = T.grad(cost, parameters)\n",
        "  updates = []\n",
        "  for p, g in zip(parameters, grads):\n",
        "    update_p = p - lr*g\n",
        "    \n",
        "    updates.append((p, update_p))\n",
        "    \n",
        "  return updates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzRXn8o8fvnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizer_update_momentum(cost, parameters, lr, mu=0.9):\n",
        "  grads = T.grad(cost, parameters)\n",
        "  updates = []\n",
        "  for p, g in zip(parameters, grads):\n",
        "    # momentum\n",
        "\t  zeros = np.zeros_like(p.get_value(), dtype=np.float32)\n",
        "\t  m = theano.shared(zeros)\n",
        "\t  new_m = mu*m - lr*g\n",
        "\n",
        "\t\t# param update\n",
        "\t  update_p = p + new_m\n",
        "\n",
        "\t\t# append the updates\n",
        "\t  updates.append((p, update_p))\n",
        "    \n",
        "  return updates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS6Cz4oQf38Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizer_update_rmsprop(cost, parameters, lr, decay_rate = 0.999, eps = 1e-10):\n",
        "  grads = T.grad(cost, parameters)\n",
        "  updates = []\n",
        "  for p, g in zip(parameters, grads):\n",
        "    # rmsprop\n",
        "    ones = np.ones_like(p.get_value(), dtype=np.float32)\n",
        "    c = theano.shared(ones)\n",
        "    c = decay_rate*c + (1-decay_rate)*g*g\n",
        "    update_p = p - lr*g / (np.sqrt(c) + eps)\n",
        "    \n",
        "    updates.append((p, update_p))\n",
        "    \n",
        "  return updates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmDn1hvNf47K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizer_update_adam(cost, parameters, lr, beta1 = 0.9, beta2 = 0.999, eps = 1e-8):\n",
        "  grads = T.grad(cost, parameters)\n",
        "  updates = []\n",
        "  t=1\n",
        "  for p, g in zip(parameters, grads):\n",
        "    # adam\n",
        "    zeros_1 = np.zeros_like(p.get_value(), dtype=np.float32)\n",
        "    m = theano.shared(zeros_1)\n",
        "    new_m = beta1*m + (1-beta1)*g\n",
        "\n",
        "    zeros_2 = np.zeros_like(p.get_value(), dtype=np.float32)\n",
        "    v = theano.shared(zeros_2)\n",
        "    new_v = beta2*v + (1-beta2)*g*g\n",
        "    \n",
        "    correction1 = 1-beta1 ** t\n",
        "    hat_new_m = new_m / correction1\n",
        "    \n",
        "    correction2 = 1-beta2 ** t\n",
        "    hat_new_v = new_v / correction2\n",
        "    \n",
        "    t += 1\n",
        "    \n",
        "    update_p = p - lr*hat_new_m / np.sqrt(hat_new_v + eps)\n",
        "    \n",
        "    updates.append((p, update_p))\n",
        "    \n",
        "  return updates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4gchBQDcmRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HiddenLayers():\n",
        "  def __init__(self, D, M):\n",
        "    self.D = D\n",
        "    self.M = M\n",
        "    W = np.random.randn(D, M) / np.sqrt(D)\n",
        "    b = np.random.randn(M)\n",
        "    self.W = theano.shared(W)\n",
        "    self.b = theano.shared(b)\n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def HiddenLayers_forward(self, X):\n",
        "    return T.nnet.relu(X.dot(self.W)+self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGqdmQlJ6mhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FinalLayers():\n",
        "  def __init__(self, M, K):\n",
        "    self.M = M\n",
        "    self.K = K\n",
        "    W = np.random.randn(M, K) / np.sqrt(M)\n",
        "    b = np.random.randn(K)\n",
        "    self.W = theano.shared(W)\n",
        "    self.b = theano.shared(b)\n",
        "    self.params = [self.W, self.b]\n",
        "    \n",
        "  def FinalLayers_forward(self, Z):\n",
        "    return T.nnet.softmax(Z.dot(self.W)+self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jThr-fZsWjGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ANN():\n",
        "  def __init__(self, size):\n",
        "    self.size = size\n",
        "    \n",
        "  def fit(self, Xtrain, Ytrain, Xtest, Ytest, lr=10e-2, reg=0.01, training_epochs=10, batch_sz=500):\n",
        "    Xtrain = Xtrain.astype(np.float32)\n",
        "    Ytrain = Ytrain.astype(np.int32)\n",
        "    \n",
        "    Xtest = Xtest.astype(np.float32)\n",
        "    Ytest = Ytest.astype(np.int32)\n",
        "    \n",
        "    N,D = Xtrain.shape\n",
        "    K = len(set(Ytrain))\n",
        "    \n",
        "    self.layers=[]\n",
        "    h = HiddenLayers(D,self.size)\n",
        "    self.layers.append(h)\n",
        "    \n",
        "    f = FinalLayers(self.size,K)\n",
        "    self.layers.append(f)\n",
        "    \n",
        "    self.parameters = []\n",
        "    for obj in self.layers:                # first obj is h and second obj is f\n",
        "      #self.parameters.append(obj.params)\n",
        "      self.parameters += obj.params\n",
        "    #print(self.parameters)                [<TensorType(float64, matrix)>, <TensorType(float64, vector)>, <TensorType(float64, matrix)>, <TensorType(float64, vector)>]\n",
        "    \n",
        "    X = T.fmatrix('X')\n",
        "    Y = T.ivector('Y')\n",
        "    pY = self.th_forward(X)\n",
        "    \n",
        "    rcost = reg*T.sum([(p*p).sum() for p in self.parameters])\n",
        "    #for p in self.parameters:\n",
        "      #print(p)                            <TensorType(float64, matrix)>\n",
        "      #                                    <TensorType(float64, vector)>\n",
        "      #                                    <TensorType(float64, matrix)>\n",
        "      #                                    <TensorType(float64, vector)>\n",
        "    cost = -T.mean(T.log(pY[T.arange(Y.shape[0]), Y])) + rcost\n",
        "    \n",
        "    #updates = optimizer_update(cost, self.parameters, lr)\n",
        "    #updates = optimizer_update_momentum(cost, self.parameters, lr)\n",
        "    #updates = optimizer_update_rmsprop(cost, self.parameters, lr)\n",
        "    updates = optimizer_update_adam(cost, self.parameters, lr)\n",
        "    \n",
        "    train_op = theano.function(inputs=[X,Y], updates=updates)\n",
        "    \n",
        "    pred = self.th_forward(X)\n",
        "    prediction = T.argmax(pred, axis=1)\n",
        "    test_op = theano.function(inputs=[X,Y], outputs=[cost,prediction])\n",
        "    \n",
        "    n_batches = N // batch_sz\n",
        "    costs = []\n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "      for j in range(n_batches):\n",
        "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        Ybatch = Ytrain[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "        \n",
        "        train_op(Xbatch, Ybatch)\n",
        "        \n",
        "        if j % 1 == 0:\n",
        "          c, p = test_op(Xtest, Ytest)\n",
        "          costs.append(c)\n",
        "          e = np.mean(p != Ytest)\n",
        "          print(\"Epoch\", (epoch + 1), \": cost =\", c, \"error rate =\", e)\n",
        "          \n",
        "    plt.plot(costs, label=\"cost\")\n",
        "    plt.show()\n",
        "  \n",
        "  def th_forward(self, X):\n",
        "    for obj in self.layers[:-1]:           # this obj is h\n",
        "      Z = obj.HiddenLayers_forward(X)\n",
        "    for obj in self.layers[-1:]:           # this obj is f\n",
        "      pY = obj.FinalLayers_forward(Z)\n",
        "    return pY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hloy8ZoBSgSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  data_train = df_train.values\n",
        "  data_test = df_test.values\n",
        "\n",
        "  Xtrain = data_train[:,1:]\n",
        "  Ytrain = data_train[:,0]\n",
        "\n",
        "  Xtest = data_test[:,1:]\n",
        "  Ytest = data_test[:,0]\n",
        "  \n",
        "  # Normalization\n",
        "  Xtrain = (Xtrain - Xtrain.mean(axis=0)) / Xtrain.std(axis=0)\n",
        "  Xtest = (Xtest - Xtest.mean(axis=0)) / Xtest.std(axis=0)\n",
        "  \n",
        "  model=ANN(128)\n",
        "  model.fit(Xtrain, Ytrain, Xtest, Ytest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvESV520VWl1",
        "colab_type": "code",
        "outputId": "727e6898-151e-4777-f3cc-af1c6450788d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : cost = 49.40307621427024 error rate = 0.6096\n",
            "Epoch 1 : cost = 67.61892181288789 error rate = 0.6405\n",
            "Epoch 1 : cost = 86.67452040455645 error rate = 0.793\n",
            "Epoch 1 : cost = 48.641736778227724 error rate = 0.6916\n",
            "Epoch 1 : cost = 70.64564964203981 error rate = 0.6265\n",
            "Epoch 1 : cost = 76.77240224284765 error rate = 0.5181\n",
            "Epoch 1 : cost = 62.455074696836796 error rate = 0.7321\n",
            "Epoch 1 : cost = 51.40767479530475 error rate = 0.4591\n",
            "Epoch 1 : cost = 90.6460865028039 error rate = 0.658\n",
            "Epoch 1 : cost = 62.84278976387584 error rate = 0.4884\n",
            "Epoch 1 : cost = 86.53315165822113 error rate = 0.5692\n",
            "Epoch 1 : cost = 62.95846682782472 error rate = 0.5103\n",
            "Epoch 1 : cost = 86.56711256661576 error rate = 0.5161\n",
            "Epoch 1 : cost = 100.19673115227137 error rate = 0.6541\n",
            "Epoch 1 : cost = 61.990041471326975 error rate = 0.5644\n",
            "Epoch 1 : cost = 74.69775593085527 error rate = 0.5659\n",
            "Epoch 1 : cost = 104.67850106094141 error rate = 0.6999\n",
            "Epoch 1 : cost = 68.6137253739178 error rate = 0.4687\n",
            "Epoch 1 : cost = 109.89530152314607 error rate = 0.4673\n",
            "Epoch 1 : cost = 70.76308029755775 error rate = 0.4931\n",
            "Epoch 1 : cost = 126.51621942505503 error rate = 0.7019\n",
            "Epoch 1 : cost = 60.52994615746806 error rate = 0.4721\n",
            "Epoch 1 : cost = 99.08679018053239 error rate = 0.6019\n",
            "Epoch 1 : cost = 79.52835564751223 error rate = 0.4354\n",
            "Epoch 1 : cost = 85.05115584124226 error rate = 0.4325\n",
            "Epoch 1 : cost = 75.35598094291568 error rate = 0.4797\n",
            "Epoch 1 : cost = 113.23639938590503 error rate = 0.6169\n",
            "Epoch 1 : cost = 76.35692067549353 error rate = 0.4231\n",
            "Epoch 1 : cost = 118.08430492672463 error rate = 0.5743\n",
            "Epoch 1 : cost = 73.7876589193233 error rate = 0.4605\n",
            "Epoch 1 : cost = 139.42615950533536 error rate = 0.5642\n",
            "Epoch 1 : cost = 95.04113691081595 error rate = 0.5283\n",
            "Epoch 1 : cost = 95.09677090205618 error rate = 0.4288\n",
            "Epoch 1 : cost = 95.40869547203127 error rate = 0.5581\n",
            "Epoch 1 : cost = 100.68056008117108 error rate = 0.497\n",
            "Epoch 1 : cost = 99.95865297894296 error rate = 0.5852\n",
            "Epoch 1 : cost = 106.89482381904695 error rate = 0.3797\n",
            "Epoch 1 : cost = 111.82730097226738 error rate = 0.6308\n",
            "Epoch 1 : cost = 96.99909943487113 error rate = 0.4407\n",
            "Epoch 1 : cost = 111.96173696406635 error rate = 0.5131\n",
            "Epoch 1 : cost = 141.7826395075841 error rate = 0.5116\n",
            "Epoch 1 : cost = 95.5178628075362 error rate = 0.5174\n",
            "Epoch 1 : cost = 105.10349943430633 error rate = 0.4603\n",
            "Epoch 1 : cost = 82.84776225749532 error rate = 0.449\n",
            "Epoch 1 : cost = 125.79485057538992 error rate = 0.5202\n",
            "Epoch 1 : cost = 84.61755952637229 error rate = 0.5183\n",
            "Epoch 1 : cost = 133.08650008140717 error rate = 0.5825\n",
            "Epoch 1 : cost = 90.98642141328233 error rate = 0.4104\n",
            "Epoch 1 : cost = 123.94259890409425 error rate = 0.4673\n",
            "Epoch 1 : cost = 98.59317529879755 error rate = 0.5422\n",
            "Epoch 1 : cost = 144.6516846839525 error rate = 0.5925\n",
            "Epoch 1 : cost = 99.08655160756088 error rate = 0.4006\n",
            "Epoch 1 : cost = 126.55175832229435 error rate = 0.4526\n",
            "Epoch 1 : cost = 98.21153112818733 error rate = 0.4072\n",
            "Epoch 1 : cost = 149.99696082503306 error rate = 0.479\n",
            "Epoch 1 : cost = 93.08544474139532 error rate = 0.4077\n",
            "Epoch 1 : cost = 144.81344185393542 error rate = 0.5878\n",
            "Epoch 1 : cost = 82.19428090326548 error rate = 0.3734\n",
            "Epoch 1 : cost = 163.50598308663763 error rate = 0.6738\n",
            "Epoch 1 : cost = 77.3769912495273 error rate = 0.3678\n",
            "Epoch 1 : cost = 143.4398267499288 error rate = 0.5713\n",
            "Epoch 1 : cost = 66.87408959665383 error rate = 0.3083\n",
            "Epoch 1 : cost = 164.93700534119512 error rate = 0.5683\n",
            "Epoch 1 : cost = 84.64892274413683 error rate = 0.4724\n",
            "Epoch 1 : cost = 154.41753461973255 error rate = 0.5608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-520-b985c2114c26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-519-7428c3c0efb2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mANN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-518-88dd5d13d6be>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xtrain, Ytrain, Xtest, Ytest, lr, reg, training_epochs, batch_sz)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m           \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m           \u001b[0mcosts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m           \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/tensor/basic.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   5968\u001b[0m         \u001b[0;31m# gives a numpy float object but we need to return a 0d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5969\u001b[0m         \u001b[0;31m# ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5970\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}